---
title: "p8105_hw6_sw3737"
author: "Shiqi Wu"
date: "2023-11-30"
output: github_document
---

```{r setup, include=FALSE}
library(rnoaa)
library(dplyr)
library(ggplot2)
library(broom)
library(tidyverse)
library(boot)
library(modelr)
library(purrr)
library(crossval)
```

# Problem 2

## Download the data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31"
  ) |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10
  ) |>
  select(name, id, everything())
```

## Define the bootstrap function
```{r}
bootstrap_fn = function(data) {
  sample_df = data |> sample_n(nrow(data), replace = TRUE)
  model = lm(tmax ~ tmin + prcp, data = sample_df)
  tidy_model = broom::tidy(model)
  glance_model = broom::glance(model)
  
  estimates = pull(tidy_model, "estimate")
  beta1_beta2 = estimates[2] * estimates[3]
  if (beta1_beta2 > 0) {
    log_beta1_beta2 = log(beta1_beta2)
  } else {
    log_beta1_beta2 = NA
  }
  r_squared = pull(glance_model, "r.squared")
  
  return(c(r_squared, log_beta1_beta2))
}
```

## Perform bootstrap
```{r}
set.seed(123)
bootstrap_results = replicate(5000, bootstrap_fn(weather_df))

bootstrap_df = as.data.frame(t(bootstrap_results))
names(bootstrap_df) = c("r_squared", "log_beta1_beta2")
```

## Plot the distributions
```{r}
ggplot(bootstrap_df, aes(x = r_squared)) +
  geom_density(fill = "lightblue") +
  labs(title = "Distribution of r^2 Estimates", x = "r^2", y = "Frequency")

ggplot(bootstrap_df, aes(x = log_beta1_beta2)) +
  geom_density(fill = "pink") +
  labs(title = "Distribution of log(beta1 * beta2) Estimates", x = "log(beta1 * beta2)", y = "Frequency")
```

The first histogram shows a slightly right-skewed distribution of r^2 estimates, clustering around values between 0.90 and 0.94, with a peak around 0.92. It indicates a common range of variance explained by the model in the bootstrap samples.

The second histogram a right-skewed distribution of the logarithm of the beta coefficient, clustering around values between -8 and -4, with a peak around -6. The distribution has a left tail, indicating that some bootstrap samples resulted in lower estimates for the product of the coefficients.

## Calculate and print the 95% confidence intervals
```{r}
r_squared_ci = quantile(pull(bootstrap_df, "r_squared"), c(0.025, 0.975), na.rm = TRUE)
log_beta1_beta2_ci = quantile(pull(bootstrap_df, "log_beta1_beta2"), c(0.025, 0.975), na.rm = TRUE)

print(paste("95% CI for r^2: Lower Bound = ", r_squared_ci[1], ", Upper Bound = ", r_squared_ci[2]))
print(paste("95% CI for log(beta1 * beta2): Lower Bound = ", log_beta1_beta2_ci[1], ", Upper Bound = ", log_beta1_beta2_ci[2]))
```

95% CI for r^2: Lower Bound =  0.888207887270769 , Upper Bound =  0.94025517661439

95% CI for log(beta1 * beta2): Lower Bound =  -9.0632139063287 , Upper Bound =  -4.61926736850544

# Problem 3

## Load and Clean the Data
```{r}
birthweight = read.csv("data/birthweight.csv")
birthweight_df = 
  birthweight |>
  janitor::clean_names() |>
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
  ) |>
  drop_na()
```

## Regression Model
```{r}
model = lm(bwt ~ blength + gaweeks + ppbmi + smoken + wtgain + babysex + bhead + frace, data = birthweight_df)

broom::tidy(model)
broom::glance(model)

summary(model)
```

### Modeling Process
(1) Initial model: I used a linear regression to build a model predicting baby's birth weight, the choice of predictors was based on my understanding of what factors might influence birth weight. It included `length`, `gaweeks`, `malform`, `ppbmi`, `smoken` and `wtgain`.
(2) Adjust model (data-driven approach): Upon observing that the current r^2 is relatively low, I was opting to adjust the model by removing `malform` (as its p-value exceeds 0.05), introducing `babysex`, `bhead` and `frace` (which increase r^2) as additional predictors. Now it has a stronger correlation with birth weight.

## Residual Analysis
```{r}
birthweight_df = birthweight_df |>
  add_predictions(model) |>
  add_residuals(model)

ggplot(birthweight_df, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  labs(x = "Fitted values", y = "Residuals") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red")
```

### Interpretation of Plot
The majority of the data points are clustered around the horizontal line at zero. However, there is a pattern where the residuals appear to fan out as the fitted values increase, suggesting potential heteroscedasticity. A few outliers are also evident, particularly for larger residuals.

## Compare Models Using Cross-Validated Prediction Error
```{r}
model_1 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
model_2 = lm(bwt ~ bhead * blength * babysex, data = birthweight_df)

cv_df = 
  crossv_mc(birthweight_df, 100)
cv_df = cv_df |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) |>
  mutate(
    model = map (train, \(df) lm(bwt ~ blength + gaweeks + ppbmi + smoken + wtgain + babysex + bhead + frace, data = df)),
    model_1 = map (train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_2 = map (train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))
  ) |>
  mutate(
    rmse_model = map2_dbl(model, test, \(model, df) rmse(model,df)),
    rmse_model_1 = map2_dbl(model_1, test, \(model, df) rmse(model,df)),
    rmse_model_2 = map2_dbl(model_2, test, \(model, df) rmse(model,df))
  )

summary(cv_df)
```

## Create a Violin Plot
```{r}
cv_df_long = cv_df |>
  select(rmse_model, rmse_model_1, rmse_model_2) |>
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse"
  ) |>
  mutate(model = factor(model, levels = c("rmse_model", "rmse_model_1", "rmse_model_2")))

ggplot(cv_df_long, aes(x = model, y = rmse, fill = model)) +
  geom_violin(trim = FALSE) +
  labs(
    title = "Comparison of RMSE Across Models",
    x = "Model",
    y = "Root Mean Squared Error (RMSE)"
  ) +
  theme_minimal()
```

My model has the widest distribution, indicating variability in its prediction errors across the cross-validation folds. The rmse_model_1 (length and gestational age) has the narrowest distribution, suggesting more consistent predictions. The rmse_model_2 (interaction of head circumference, length, sex) has a distribution that is more compact than my model but less so than rmse_model_1. The median RMSE appears to be lowest for rmse_model_1, indicating it may have the best predictive accuracy on average, although the plot suggests there is some overlap in the RMSE distributions of the three models.
